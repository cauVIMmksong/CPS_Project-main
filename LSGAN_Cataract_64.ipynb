{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageFile, Image\n",
    "import cv2\n",
    "\n",
    "from CPS import CPS\n",
    "#from CelebDataset import CelebDataset\n",
    "#from MyModels import GeneratorModel, DiscriminatorModel\n",
    "import imageio as imageio\n",
    "\n",
    "# 코드 실행결과의 동일성을 위해 무작위 시드를 설정합니다\n",
    "manualSeed = 416\n",
    "#manualSeed = random.randint(1, 10000) # 만일 새로운 결과를 원한다면 주석을 없애면 됩니다\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU Check\n",
    "\n",
    "ngpu = 1\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "print(device,\"is available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA set check and load\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                transforms.Resize(64),\n",
    "                transforms.CenterCrop(64),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                ])\n",
    "dataset = CPS('images/CPS_Dog_Cataract_Rand', transform=transform)\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=64, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view function and check the sample imgs\n",
    "\n",
    "def view_samples(images):\n",
    "    img = torchvision.utils.make_grid(images, padding=2, normalize=True)\n",
    "    img = img.cpu().numpy()\n",
    "    plt.figure(figsize = (8, 8))\n",
    "    plt.imshow(np.transpose(img, (1,2,0)))\n",
    "    plt.show()\n",
    "    \n",
    "test = iter(dataloader)\n",
    "sample = next(test)\n",
    "print(sample.size())\n",
    "view_samples(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the progress of learning result pics\n",
    "\n",
    "def save_progress(images, epoch, step):\n",
    "    img = torchvision.utils.make_grid(images, padding=2, normalize=True)\n",
    "    img = img.cpu().numpy()\n",
    "    img = np.transpose(img, (1,2,0))\n",
    "    img = np.uint8(img*255)\n",
    "    imageio.imwrite(f\"Results/LSGAN_Cataract3/{epoch}-{step}.jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model's state\n",
    "\n",
    "def save_model_state(model, optimizer, loss, epoch, name):\n",
    "    model_path = f\"saved_models/{name}{epoch}.pt\"\n",
    "    state_dict = {\n",
    "        'epoch' : epoch,\n",
    "        'model_state_dict' : model.state_dict(),\n",
    "        'opt_state_dict' : optimizer.state_dict(),\n",
    "        'training_loss' : loss,\n",
    "    }\n",
    "    torch.save(state_dict, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved model\n",
    "\n",
    "def load_model_state(model, filename):\n",
    "    model_info = torch.load(f\"saved_models/{filename}.pt\")\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    optimizer.load_state_dict(model_info[\"opt_state_dict\"])\n",
    "    model.load_state_dict(model_info[\"model_state_dict\"])\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making loss graph function\n",
    "\n",
    "def plot_losses(gen, dis):\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    ax = plt.subplot(111)\n",
    "    ax.plot(gen, label=\"Generator\")\n",
    "    ax.plot(dis, label=\"Discriminator\")\n",
    "    plt.title(\"PCA_GAN Gen/Dis losses\")\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize step\n",
    "\n",
    "n_z = 100 # 잠재공간 벡터 크기(생성자 입력값 크기)\n",
    "n_c = 3 # 이미지 채널 갯수(RGB)\n",
    "n_feature_maps_g = 64 # 생성자의 특징 맵 크기\n",
    "n_feature_maps_d = 64 # 구분자의 특징 맵 크기\n",
    "epochs = 300\n",
    "\n",
    "fixed_noise = torch.randn(64, n_z, 1, 1).to(device)\n",
    "torch.save(fixed_noise, \"fixed_noise.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "class DiscriminatorModel(nn.Module):\n",
    "    def __init__(self, n_c, n_fmps):\n",
    "        super(DiscriminatorModel, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(n_c, n_fmps, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(n_fmps, n_fmps*2, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(n_fmps*2),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(n_fmps*2, n_fmps*4, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(n_fmps*4),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(n_fmps*4, n_fmps*8, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(n_fmps*8),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(n_fmps * 8, 1, 4, stride=1, padding=0),\n",
    "        )\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "        self.net.apply(weights_init)\n",
    "        self.linear.apply(weights_init)\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        #print(x.shape)\n",
    "        x = self.linear(x)\n",
    "        #print(x.shape)\n",
    "        return x.view(-1, 1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorModel(nn.Module):\n",
    "    def __init__(self, n_z, n_fmps, n_c):\n",
    "        super(GeneratorModel, self).__init__()\n",
    "        self.n_z = n_z\n",
    "        self.net = nn.Sequential(\n",
    "            nn.ConvTranspose2d(self.n_z, n_fmps*8, 4, 1, 0),\n",
    "            nn.BatchNorm2d(n_fmps*8),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.ConvTranspose2d(n_fmps*8, n_fmps*4, 4, 2, 1),\n",
    "            nn.BatchNorm2d(n_fmps*4),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.ConvTranspose2d(n_fmps*4, n_fmps*2, 4, 2, 1),\n",
    "            nn.BatchNorm2d(n_fmps*2),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.ConvTranspose2d(n_fmps*2, n_fmps*1, 4, 2, 1),\n",
    "            nn.BatchNorm2d(n_fmps*1),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.ConvTranspose2d(n_fmps, n_c, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.net.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.n_z, 1, 1)\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_losses = [] # 생성자 loss\n",
    "d_losses = [] # 구분자 loss\n",
    "\n",
    "Dis = DiscriminatorModel(n_c, n_feature_maps_d).to(device) # 구분자 모델 생성\n",
    "Gen = GeneratorModel(n_z, n_feature_maps_g, n_c).to(device) # 생성자 모델 생성\n",
    "\n",
    "lr_g = 2e-4 # 생성자 learning rate 설정\n",
    "lr_d = 2e-4 # 구분자 learning rate 설정\n",
    "Dis_opt = optim.Adam(Dis.parameters(), lr=lr_d, betas=(0.5, 0.999)) # 구분자 옵티마이저 설정\n",
    "Gen_opt = optim.Adam(Gen.parameters(), lr=lr_g, betas=(0.5, 0.999)) # 생성자 옵티마이저 설정\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "len(dataloader)\n",
    "checkpoint = int(len(dataloader)/10)\n",
    "\n",
    "d_running_loss = 0.\n",
    "g_running_loss = 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Dis)\n",
    "print(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training part\n",
    "\n",
    "for e in range(1, epochs+1):\n",
    "    print(f\"Epoch {e} started.\")\n",
    "    for i, batch in enumerate(dataloader, 1):\n",
    "        \n",
    "        batch_size = batch.size(0)\n",
    "        real_image = batch.to(device)\n",
    "\n",
    "        fake_label = torch.zeros(batch_size, 1, 1, 1).to(device)\n",
    "        real_label = torch.ones(batch_size, 1, 1, 1).to(device)\n",
    "\n",
    "        Dis.zero_grad()\n",
    "        D_x = Dis(real_image)\n",
    "        D_x_loss = criterion(D_x, real_label)\n",
    "        d_running_loss += D_x_loss.item()\n",
    "        D_x_loss.backward()\n",
    "\n",
    "        z = torch.randn(batch_size, n_z, 1, 1).to(device)  # 일반적인 noise\n",
    "\n",
    "        G_z = Gen(z)\n",
    "        D_G_z = Dis(G_z.detach())\n",
    "        D_G_z_loss = criterion(D_G_z, fake_label)\n",
    "        d_running_loss += D_G_z_loss.item()\n",
    "        D_G_z_loss.backward()\n",
    "        \n",
    "        Dis_opt.step()\n",
    "        \n",
    "        Gen.zero_grad()\n",
    "        G_z = Gen(z)\n",
    "        D_G_z = Dis(G_z)\n",
    "        G_z_loss = criterion(D_G_z, real_label)\n",
    "        g_running_loss += G_z_loss.item()\n",
    "        \n",
    "        G_z_loss.backward()    \n",
    "        Gen_opt.step()\n",
    "        \n",
    "        if i % checkpoint == 0:\n",
    "            \n",
    "            g_current_loss = g_running_loss/checkpoint\n",
    "            d_current_loss = d_running_loss/checkpoint\n",
    "            g_losses.append(g_current_loss)\n",
    "            d_losses.append(d_current_loss)\n",
    "            print(f\"[Generator loss: {g_current_loss}, Discriminator loss: {d_current_loss}]\")\n",
    "\n",
    "            if (i * checkpoint) % 10 == 0:\n",
    "                fixed_z_images = Gen(fixed_noise).detach()\n",
    "                save_progress(fixed_z_images, e, i//checkpoint)\n",
    "            \n",
    "            g_running_loss = 0.\n",
    "            d_running_loss = 0.\n",
    "    if e % 10 == 0:\n",
    "        save_model_state(Gen, Gen_opt, g_current_loss, e, \"Generator\")\n",
    "        save_model_state(Dis, Dis_opt, d_current_loss, e, \"Discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(g_losses,d_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_Gloss = np.average(g_losses)\n",
    "print(\"Average Generator Loss:\", avg_Gloss)\n",
    "\n",
    "avg_Dloss = np.average(d_losses)\n",
    "print(\"Average Discriminator Loss:\",avg_Dloss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
